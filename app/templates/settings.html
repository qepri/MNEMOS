{% extends "base.html" %}

{% block content %}
<div class="min-h-screen bg-base-100">
    <div class="container mx-auto p-4 max-w-6xl">
        <!-- Header -->
        <div class="flex justify-between items-center mb-6 p-4 bg-base-200 rounded-lg">
            <div>
                <h1 class="text-2xl font-bold text-primary">‚öôÔ∏è Ollama Configuration</h1>
                <p class="text-sm text-base-content/70 mt-1">Manage your local LLM models</p>
            </div>
            <a href="/" class="btn btn-ghost btn-sm">
                <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5"
                    stroke="currentColor" class="w-5 h-5">
                    <path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5L3 12m0 0l7.5-7.5M3 12h18" />
                </svg>
                Back to Chat
            </a>
        </div>

        <!-- Hardware Stats -->
        <div class="grid grid-cols-1 md:grid-cols-3 gap-4 mb-6">
            <div class="card bg-base-200 shadow-sm">
                <div class="card-body p-4">
                    <div class="text-xs font-mono text-base-content/60 uppercase tracking-wider">Available RAM</div>
                    <div class="text-2xl font-bold text-primary" id="ram-available">Loading...</div>
                    <div class="text-xs text-base-content/70" id="ram-total">Total: ...</div>
                </div>
            </div>
            <!-- VRAM (if we could detect it easily, placeholder for now) -->
        </div>

        <!-- MAIN TABS -->
        <div role="tablist" class="tabs tabs-bordered mb-4 bg-base-200 rounded-lg p-1">
            <a role="tab" class="tab tab-active font-semibold" onclick="showTab(event, 'tab-installed')">üì¶ Installed
                Models</a>
            <a role="tab" class="tab font-semibold" onclick="showTab(event, 'tab-discover')">üîç Discover / Pull</a>
            <a role="tab" class="tab font-semibold" onclick="showTab(event, 'tab-import')">üì• Import GGUF</a>
            <a role="tab" class="tab font-semibold" onclick="showTab(event, 'tab-chat-settings')">üí¨ Chat Settings</a>
        </div>

        <!-- INSTALLED MODELS -->
        <div id="tab-installed" class="tab-content block">
            <div class="card bg-base-200 shadow-sm border border-base-300">
                <div class="card-body">
                    <div class="flex justify-between items-center mb-4">
                        <div>
                            <h2 class="card-title text-lg">üìö Your Library</h2>
                            <p class="text-xs text-base-content/60 mt-1">Select a model for chat</p>
                        </div>
                        <button class="btn btn-sm btn-primary" onclick="loadModels()">
                            <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5"
                                stroke="currentColor" class="w-4 h-4">
                                <path stroke-linecap="round" stroke-linejoin="round"
                                    d="M16.023 9.348h4.992v-.001M2.985 19.644v-4.992m0 0h4.992m-4.993 0l3.181 3.183a8.25 8.25 0 0013.803-3.7M4.031 9.865a8.25 8.25 0 0113.803-3.7l3.181 3.182m0-4.991v4.99" />
                            </svg>
                            Refresh
                        </button>
                    </div>

                    <!-- Current Model Indicator -->
                    <div class="alert mb-4 py-3 border-2" id="current-model-alert">
                        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24"
                            class="stroke-current shrink-0 w-6 h-6">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
                                d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path>
                        </svg>
                        <div>
                            <div class="text-sm font-semibold">Active Chat Model</div>
                            <div class="text-xs mt-1">
                                <span id="current-model-name" class="font-mono">None selected</span>
                            </div>
                        </div>
                    </div>

                    <div id="models-list" class="overflow-x-auto">
                        <span class="loading loading-spinner loading-md"></span>
                    </div>
                </div>
            </div>
        </div>

        <!-- DISCOVER / PULL -->
        <div id="tab-discover" class="tab-content hidden">
            <div class="card bg-base-200 shadow-sm border border-base-300">
                <div class="card-body">
                    <div class="flex justify-between items-center mb-4">
                        <h2 class="card-title">üîç Discover Models</h2>
                        <button class="btn btn-sm btn-ghost" onclick="searchLibrary()">
                            <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5"
                                stroke="currentColor" class="w-4 h-4">
                                <path stroke-linecap="round" stroke-linejoin="round"
                                    d="M16.023 9.348h4.992v-.001M2.985 19.644v-4.992m0 0h4.992m-4.993 0l3.181 3.183a8.25 8.25 0 0013.803-3.7M4.031 9.865a8.25 8.25 0 0113.803-3.7l3.181 3.182m0-4.991v4.99" />
                            </svg>
                            Refresh
                        </button>
                    </div>

                    <!-- Search Bar and Filters -->
                    <div class="flex gap-2 mb-4">
                        <div class="join flex-1">
                            <input type="text" id="search-query" placeholder="Search models on Hugging Face..."
                                class="input input-bordered w-full join-item" oninput="debounceSearch()" />
                            <button class="btn btn-ghost join-item" onclick="searchLibrary()">
                                <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24"
                                    stroke-width="1.5" stroke="currentColor" class="w-5 h-5">
                                    <path stroke-linecap="round" stroke-linejoin="round"
                                        d="M21 21l-5.197-5.197m0 0A7.5 7.5 0 105.196 5.196a7.5 7.5 0 0010.607 10.607z" />
                                </svg>
                            </button>
                        </div>
                        <select id="sort-select" class="select select-bordered" onchange="searchLibrary()">
                            <option value="downloads">Most Downloaded</option>
                            <option value="trending">Trending</option>
                            <option value="created">Recently Added</option>
                        </select>
                    </div>

                    <!-- Model Cards Grid -->
                    <div id="models-catalog" class="grid grid-cols-1 gap-3 max-h-[600px] overflow-y-auto">
                        <span class="loading loading-spinner loading-md mx-auto"></span>
                    </div>

                    <!-- Active Downloads Tracker -->
                    <div id="downloads-tracker" class="mt-4 space-y-2 hidden">
                        <div class="flex justify-between items-center mb-2">
                            <h3 class="font-semibold text-sm">Active Downloads</h3>
                            <span id="download-count" class="badge badge-primary badge-sm">0</span>
                        </div>
                        <div id="downloads-list" class="space-y-2"></div>
                    </div>
                </div>
            </div>
        </div>

        <!-- IMPORT GGUF -->
        <div id="tab-import" class="tab-content hidden">
            <div class="card bg-base-200 shadow-sm border border-base-300">
                <div class="card-body">
                    <h2 class="card-title">Import GGUF File</h2>
                    <div class="alert alert-warning text-sm mb-4">
                        <svg xmlns="http://www.w3.org/2000/svg" class="stroke-current shrink-0 h-6 w-6" fill="none"
                            viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
                                d="M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z" />
                        </svg>
                        <span>1. Copy your .gguf file to <b>rag_app/ollama_models/import</b> folder.<br>
                            2. Click Refresh to see it below.<br>
                            3. Click Import to register it with Ollama.</span>
                    </div>

                    <div class="flex justify-end mb-2">
                        <button class="btn btn-sm btn-ghost" onclick="scanImports()">Refresh Files</button>
                    </div>

                    <div id="import-list" class="space-y-2">
                        <span class="opacity-50 text-sm">No files found.</span>
                    </div>
                </div>
            </div>
        </div>

        <!-- CHAT SETTINGS -->
        <div id="tab-chat-settings" class="tab-content hidden">
            <div class="space-y-4">
                <!-- Conversation Context Settings -->
                <div class="card bg-base-200 shadow-sm border border-base-300">
                    <div class="card-body">
                        <h2 class="card-title text-lg mb-4">üîÑ Conversation Context</h2>

                        <!-- Enable Context Toggle -->
                        <div class="form-control mb-4">
                            <label class="label cursor-pointer justify-start gap-4">
                                <input type="checkbox" class="toggle toggle-primary" id="use-context-toggle"
                                    onchange="toggleContextSettings()">
                                <div>
                                    <span class="label-text font-semibold">
                                        Use Conversation History
                                    </span>
                                    <p class="text-xs text-base-content/60 mt-1">
                                        Include previous messages when answering questions. This helps the LLM
                                        understand follow-up questions and maintain context.
                                    </p>
                                </div>
                            </label>
                        </div>

                        <!-- Max Context Messages -->
                        <div class="form-control" id="context-range-container">
                            <label class="label">
                                <span class="label-text font-semibold">Context Window (messages)</span>
                                <span class="label-text-alt" id="context-range-value">10 messages</span>
                            </label>
                            <input type="range" min="0" max="20" value="10" class="range range-primary range-sm"
                                id="max-context-range" step="5" oninput="updateRangeValue()">
                            <div class="flex justify-between text-xs px-2 mt-1">
                                <span>0</span>
                                <span>5</span>
                                <span>10</span>
                                <span>15</span>
                                <span>20</span>
                            </div>
                            <p class="text-xs text-base-content/60 mt-2">
                                Higher values provide more context but may slow down responses and increase token usage.
                            </p>
                        </div>
                    </div>
                </div>
            </div>

            <!-- LLM Client Configuration -->
            <div class="card bg-base-200 shadow-sm border border-base-300">
                <div class="card-body">
                    <h2 class="card-title text-lg mb-4">ü§ñ AI Client Configuration</h2>

                    <!-- Provider Select -->
                    <div class="form-control mb-4">
                        <label class="label">
                            <span class="label-text font-semibold">LLM Provider</span>
                        </label>
                        <select class="select select-bordered select-sm w-full" id="llm-provider-select"
                            onchange="updateLLMConfigVisibility()">
                            <option value="openai">OpenAI</option>
                            <option value="anthropic">Anthropic (Claude)</option>
                            <option value="lm_studio">LM Studio (Local)</option>
                            <option value="ollama">Ollama (Local)</option>
                        </select>
                    </div>

                    <!-- OpenAI Key -->
                    <div class="form-control mb-4 hidden" id="config-openai">
                        <label class="label">
                            <span class="label-text">OpenAI API Key</span>
                        </label>
                        <input type="password" placeholder="sk-..." class="input input-bordered input-sm w-full"
                            id="openai-api-key">
                    </div>

                    <!-- Anthropic Key -->
                    <div class="form-control mb-4 hidden" id="config-anthropic">
                        <label class="label">
                            <span class="label-text">Anthropic API Key</span>
                        </label>
                        <input type="password" placeholder="sk-ant-..." class="input input-bordered input-sm w-full"
                            id="anthropic-api-key">
                    </div>

                    <!-- Local URL -->
                    <div class="form-control mb-4 hidden" id="config-local-url">
                        <label class="label">
                            <span class="label-text">Base URL</span>
                        </label>
                        <input type="text" placeholder="http://host.docker.internal:1234/v1"
                            class="input input-bordered input-sm w-full" id="local-llm-base-url">
                        <label class="label">
                            <span class="label-text-alt text-base-content/60">Ensure your local server is running and
                                accessible from Docker.</span>
                        </label>
                    </div>
                </div>
            </div>

            <!-- RAG Processing Settings -->
            <div class="card bg-base-200 shadow-sm border border-base-300">
                <div class="card-body">
                    <h2 class="card-title text-lg mb-4">üìÑ Document Processing (RAG)</h2>
                    <div class="alert alert-info text-xs mb-4">
                        Changes here apply only to <b>newly processed</b> documents. Existing documents must be
                        re-processed.
                    </div>

                    <!-- Whisper Model -->
                    <div class="form-control mb-4">
                        <label class="label">
                            <span class="label-text font-semibold">Transcription Model (Whisper)</span>
                        </label>
                        <select class="select select-bordered select-sm w-full" id="whisper-model-select">
                            <option value="base">Fast (Base) - Good for testing</option>
                            <option value="small">Balanced (Small) - Recommended</option>
                            <option value="medium">Accurate (Medium) - High quality, needs GPU</option>
                        </select>
                        <label class="label">
                            <span class="label-text-alt text-base-content/60">Effect updates on next processed
                                document.</span>
                        </label>
                    </div>

                    <!-- Chunk Size -->
                    <div class="form-control mb-4">
                        <label class="label">
                            <span class="label-text font-semibold">Chunk Size (characters)</span>
                        </label>
                        <div class="flex items-center gap-4">
                            <input type="range" min="128" max="2048" value="512"
                                class="range range-primary range-sm flex-1" id="chunk-size-range" step="64"
                                oninput="updateRahSettingsDisplay('size')">
                            <input type="number" min="128" max="2048" value="512"
                                class="input input-bordered input-sm w-24 text-center font-mono" id="chunk-size-input"
                                oninput="updateRahSettingsDisplay('size_input')">
                        </div>
                        <div class="flex justify-between text-xs px-2 mt-1 text-base-content/50 font-mono">
                            <span>128</span>
                            <span>|</span>
                            <span>2048</span>
                        </div>
                    </div>

                    <!-- Chunk Overlap -->
                    <div class="form-control">
                        <label class="label">
                            <span class="label-text font-semibold">Chunk Overlap (characters)</span>
                        </label>
                        <div class="flex items-center gap-4">
                            <input type="range" min="0" max="512" value="50"
                                class="range range-secondary range-sm flex-1" id="chunk-overlap-range" step="10"
                                oninput="updateRahSettingsDisplay('overlap')">
                            <input type="number" min="0" max="512" value="50"
                                class="input input-bordered input-sm w-24 text-center font-mono"
                                id="chunk-overlap-input" oninput="updateRahSettingsDisplay('overlap_input')">
                        </div>
                        <div class="flex justify-between text-xs px-2 mt-1 text-base-content/50 font-mono">
                            <span>0</span>
                            <span>|</span>
                            <span>512</span>
                        </div>
                    </div>
                </div>
            </div>

            <!-- System Prompts -->
            <div class="card bg-base-200 shadow-sm border border-base-300">
                <div class="card-body">
                    <div class="flex justify-between items-center mb-4">
                        <div>
                            <h2 class="card-title text-lg">üé≠ System Prompts</h2>
                            <p class="text-xs text-base-content/60 mt-1">Customize how the assistant responds</p>
                        </div>
                        <button class="btn btn-sm btn-primary" onclick="showCreatePromptModal()">
                            <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5"
                                stroke="currentColor" class="w-4 h-4">
                                <path stroke-linecap="round" stroke-linejoin="round" d="M12 4.5v15m7.5-7.5h-15" />
                            </svg>
                            New Prompt
                        </button>
                    </div>

                    <div id="prompts-list" class="space-y-2">
                        <span class="loading loading-spinner loading-md"></span>
                    </div>
                </div>
            </div>

            <!-- Save Button -->
            <div class="flex justify-end">
                <button class="btn btn-primary btn-lg" onclick="saveChatSettings()">
                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5"
                        stroke="currentColor" class="w-5 h-5">
                        <path stroke-linecap="round" stroke-linejoin="round"
                            d="M9 12.75L11.25 15 15 9.75M21 12a9 9 0 11-18 0 9 9 0 0118 0z" />
                    </svg>
                    Save Settings
                </button>
            </div>
        </div>
    </div>

</div>
</div>

<!-- Modal for Creating/Editing Prompts -->
<dialog id="prompt-modal" class="modal">
    <div class="modal-box max-w-2xl">
        <h3 class="font-bold text-lg mb-4" id="modal-title">Create System Prompt</h3>

        <div class="form-control mb-4">
            <label class="label">
                <span class="label-text font-semibold">Title</span>
            </label>
            <input type="text" id="prompt-title-input" placeholder="e.g., Technical Writer, Creative Assistant..."
                class="input input-bordered w-full">
        </div>

        <div class="form-control mb-4">
            <label class="label">
                <span class="label-text font-semibold">System Prompt Content</span>
            </label>
            <textarea id="prompt-content-input" placeholder="You are a helpful assistant that..."
                class="textarea textarea-bordered w-full h-40" rows="8"></textarea>
            <label class="label">
                <span class="label-text-alt">Describe how the assistant should behave and respond</span>
            </label>
        </div>

        <div class="modal-action">
            <button class="btn" onclick="closePromptModal()">Cancel</button>
            <button class="btn btn-primary" onclick="savePrompt()" id="save-prompt-btn">Save</button>
        </div>
    </div>
    <form method="dialog" class="modal-backdrop">
        <button>close</button>
    </form>
</dialog>

<script>
    document.addEventListener('DOMContentLoaded', () => {
        loadHardware();
        loadModels();
        scanImports();
        loadCurrentModel();
        loadChatSettings();
        loadPrompts();
        searchLibrary(); // Load model catalog
        loadActiveDownloads(); // Restore active downloads
    });

    let currentHardware = { ram_available: 0, ram_total: 0 };

    async function loadHardware() {
        try {
            const res = await fetch('/api/settings/hardware');
            const data = await res.json();
            if (data.ram_available) {
                currentHardware = data;
                document.getElementById('ram-available').textContent = (data.ram_available / 1024 / 1024 / 1024).toFixed(1) + " GB";
                document.getElementById('ram-total').textContent = "Total: " + (data.ram_total / 1024 / 1024 / 1024).toFixed(1) + " GB";
            }
        } catch (e) { console.error(e); }
    }

    function showTab(evt, infoId) {
        document.querySelectorAll('.tab').forEach(t => t.classList.remove('tab-active'));
        evt.target.classList.add('tab-active');
        document.querySelectorAll('.tab-content').forEach(c => c.classList.add('hidden'));
        document.querySelectorAll('.tab-content').forEach(c => c.classList.remove('block')); // fix daisyui weirdness

        const el = document.getElementById(infoId);
        el.classList.remove('hidden');
        el.classList.add('block');
    }

    let currentSelectedModel = null;

    async function loadCurrentModel() {
        try {
            const res = await fetch('/api/settings/current-model');
            const data = await res.json();
            currentSelectedModel = data.model;
            updateCurrentModelDisplay();
        } catch (e) { console.error(e); }
    }

    function updateCurrentModelDisplay() {
        const display = document.getElementById('current-model-name');
        const alert = document.getElementById('current-model-alert');

        if (display) {
            display.textContent = currentSelectedModel || 'None selected';
        }

        if (alert) {
            if (currentSelectedModel) {
                alert.className = 'alert alert-success mb-4 py-3 border-2';
            } else {
                alert.className = 'alert alert-warning mb-4 py-3 border-2';
            }
        }
    }

    async function selectModel(modelName) {
        try {
            const res = await fetch('/api/settings/current-model', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ model: modelName })
            });

            if (res.ok) {
                currentSelectedModel = modelName;
                updateCurrentModelDisplay();
                loadModels(); // Refresh to update radio buttons
            }
        } catch (e) {
            console.error(e);
            alert('Failed to select model');
        }
    }

    async function loadModels() {
        const listDiv = document.getElementById('models-list');
        listDiv.innerHTML = '<span class="loading loading-spinner loading-md"></span>';
        try {
            const response = await fetch('/api/settings/models');
            const data = await response.json();
            if (data.models && data.models.length > 0) {
                let html = '<div class="space-y-2">';
                data.models.forEach(model => {
                    const isSelected = model.name === currentSelectedModel;
                    const sizeGB = (model.size / 1024 / 1024 / 1024).toFixed(2);
                    const date = new Date(model.modified_at).toLocaleDateString();

                    html += `
                    <div class="flex items-center gap-3 p-3 rounded-lg bg-base-100 border border-base-300 hover:border-primary transition-colors cursor-pointer ${isSelected ? 'border-primary bg-primary/10' : ''}" onclick="selectModel('${model.name}')">
                        <input type="radio" name="model-select" class="radio radio-primary radio-sm" ${isSelected ? 'checked' : ''} onchange="selectModel('${model.name}')">
                        <div class="flex-1">
                            <div class="font-mono font-semibold text-sm">${model.name}</div>
                            <div class="text-xs text-base-content/60">${sizeGB} GB ‚Ä¢ ${date}</div>
                        </div>
                        <div class="flex items-center gap-2">
                            ${isSelected ? '<span class="badge badge-success badge-sm">Active</span>' : ''}
                            <button class="btn btn-ghost btn-xs text-error" onclick="deleteModel('${model.name}', event)" title="Delete Model">
                                <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-4 h-4">
                                    <path stroke-linecap="round" stroke-linejoin="round" d="M14.74 9l-.346 9m-4.788 0L9.26 9m9.968-3.21c.342.052.682.107 1.022.166m-1.022-.165L18.16 19.673a2.25 2.25 0 01-2.244 2.077H8.084a2.25 2.25 0 01-2.244-2.077L4.772 5.79m14.456 0a48.108 48.108 0 00-3.478-.397m-12 .562c.34-.059.68-.114 1.022-.165m0 0a48.11 48.11 0 013.478-.397m7.5 0v-.916c0-1.18-.91-2.164-2.09-2.201a51.964 51.964 0 00-3.32 0c-1.18.037-2.09 1.022-2.09 2.201v.916m7.5 0a48.667 48.667 0 00-7.5 0" />
                                </svg>
                            </button>
                        </div>
                    </div>`;
                });
                html += '</div>';
                listDiv.innerHTML = html;
            } else {
                listDiv.innerHTML = '<div class="alert alert-warning text-sm">No models found. Pull a model first!</div>';
            }
        } catch (e) {
            listDiv.innerHTML = '<div class="alert alert-error text-sm">Error loading models</div>';
        }
    }

    // DISCOVERY / SEARCH LIBRARY
    let searchTimeout;
    function debounceSearch() {
        clearTimeout(searchTimeout);
        searchTimeout = setTimeout(searchLibrary, 500);
    }

    async function searchLibrary() {
        const query = document.getElementById('search-query')?.value.trim() || '';
        const sort = document.getElementById('sort-select')?.value || 'downloads';
        const catalog = document.getElementById('models-catalog');

        catalog.innerHTML = '<span class="loading loading-spinner loading-md mx-auto"></span>';

        try {
            const res = await fetch(`/api/settings/library/search?q=${encodeURIComponent(query)}&sort=${sort}&limit=30`);
            const data = await res.json();

            if (!data.models || data.models.length === 0) {
                catalog.innerHTML = '<div class="alert alert-warning text-sm">No models found. Try a different search term.</div>';
                return;
            }

            const ramAvailableGB = currentHardware.ram_available / 1024 / 1024 / 1024;

            // Show info banner if using fallback
            let html = '';
            if (data.fallback) {
                html += '<div class="alert alert-info text-xs mb-3"><span>‚ö†Ô∏è Using offline catalog. Hugging Face API unavailable.</span></div>';
            } else {
                html += `<div class="text-xs text-base-content/60 mb-3">Found ${data.total} models from Hugging Face</div>`;
            }

            data.models.forEach(model => {
                const isCompatible = model.size_gb <= ramAvailableGB;
                const compatBadge = isCompatible
                    ? '<span class="badge badge-success badge-sm">‚úì Compatible</span>'
                    : '<span class="badge badge-warning badge-sm">‚ö† Low RAM</span>';

                const tags = model.tags.map(tag => `<span class="badge badge-ghost badge-xs">${tag}</span>`).join(' ');
                const capabilities = model.capabilities.slice(0, 3).join(', ');

                // Format numbers
                const downloads = model.downloads ? formatNumber(model.downloads) : '';
                const likes = model.likes || 0;

                const statsHtml = downloads ? `
                    <div class="flex gap-3 text-xs text-base-content/60 mb-2">
                        <span>‚¨áÔ∏è ${downloads}</span>
                        <span>‚ù§Ô∏è ${likes}</span>
                    </div>
                ` : '';

                html += `
                <div class="card bg-base-100 border border-base-300 hover:border-primary transition-all">
                    <div class="card-body p-4">
                        <div class="flex justify-between items-start mb-2">
                            <div class="flex-1">
                                <div class="flex items-center gap-2">
                                    <h3 class="font-bold text-base">${model.name}</h3>
                                    ${compatBadge}
                                </div>
                                <p class="text-xs text-base-content/60">${model.author || 'Community'} ‚Ä¢ ${model.params} parameters</p>
                                ${model.ollama_name && model.ollama_name !== model.name ?
                        `<div class="mt-1 text-xs text-info flex items-center gap-1">
                                        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-3 h-3">
                                            <path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5L21 12m0 0l-7.5 7.5M21 12H3" />
                                        </svg>
                                        Installs as <span class="font-mono font-semibold opacity-80">${model.ollama_name}</span>
                                    </div>`
                        : ''}
                            </div>
                            ${model.is_hf_only ? `
                                <a href="${model.hf_url}" target="_blank" class="btn btn-ghost btn-sm" title="Model not in Ollama library - download from HuggingFace">
                                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-4 h-4">
                                        <path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 003 8.25v10.5A2.25 2.25 0 005.25 21h10.5A2.25 2.25 0 0018 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25" />
                                    </svg>
                                    View on HF
                                </a>
                            ` : `
                                <button class="btn btn-primary btn-sm" onclick="pullModel('${escapeHtml(model.ollama_name || model.full_name)}', '${escapeHtml(model.name)}')">
                                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-4 h-4">
                                        <path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 005.25 21h13.5A2.25 2.25 0 0021 18.75V16.5M16.5 12L12 16.5m0 0L7.5 12m4.5 4.5V3" />
                                    </svg>
                                    Pull
                                </button>
                            `}
                        </div>

                        ${statsHtml}

                        <p class="text-sm text-base-content/80 mb-3">${escapeHtml(model.description)}</p>

                        <div class="flex flex-wrap gap-1 mb-2">
                            ${tags}
                        </div>

                        <div class="grid grid-cols-3 gap-2 text-xs">
                            <div>
                                <span class="text-base-content/60">Size:</span>
                                <span class="font-semibold">${model.size_gb} GB</span>
                            </div>
                            <div>
                                <span class="text-base-content/60">Min RAM:</span>
                                <span class="font-semibold">${model.min_ram_gb} GB</span>
                            </div>
                            <div>
                                <span class="text-base-content/60">Type:</span>
                                <span class="font-semibold">GGUF</span>
                            </div>
                        </div>

                        ${model.hf_url ? `
                        <div class="mt-2">
                            <a href="${model.hf_url}" target="_blank" class="text-xs text-primary hover:underline">
                                View on Hugging Face ‚Üí
                            </a>
                        </div>
                        ` : ''}
                    </div>
                </div>`;
            });

            catalog.innerHTML = html;
        } catch (e) {
            console.error('Error searching library:', e);
            catalog.innerHTML = '<div class="alert alert-error text-sm">Error loading models. Please try again.</div>';
        }
    }

    function formatNumber(num) {
        if (num >= 1000000) return (num / 1000000).toFixed(1) + 'M';
        if (num >= 1000) return (num / 1000).toFixed(1) + 'K';
        return num.toString();
    }

    function escapeHtml(text) {
        const div = document.createElement('div');
        div.textContent = text;
        return div.innerHTML;
    }

    // Download Management
    const activeDownloads = new Map();

    async function pullModel(ollamaName, displayName) {
        displayName = displayName || ollamaName;

        if (!confirm(`Download ${displayName} via Ollama? This may take several minutes depending on your connection.`)) {
            return;
        }

        // Check if already downloading
        if (activeDownloads.has(displayName)) {
            showToast('This model is already downloading', 'warning');
            return;
        }

        startPull(ollamaName, displayName);
    }

    async function startPull(ollamaName, displayName) {
        displayName = displayName || ollamaName;

        try {
            const response = await fetch('/api/settings/pull', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    model: ollamaName,
                    display_name: displayName
                })
            });

            if (!response.ok) {
                const error = await response.json();
                throw new Error(error.error || "Pull failed");
            }

            const data = await response.json();
            console.log('Started pull task:', data);

            // Add to active downloads with task tracking
            const downloadId = Date.now().toString();
            activeDownloads.set(displayName, {
                id: downloadId,
                status: 'starting',
                ollamaName,
                taskId: data.task_id,
                progress: { status: 'starting' }
            });
            updateDownloadsUI();

            // Start polling for progress updates
            await pollDownloadProgress(displayName, data.task_id);

        } catch (e) {
            console.error('Download error:', e);
            activeDownloads.delete(displayName);
            updateDownloadsUI();
            showToast(`‚ùå Failed to download ${displayName}: ${e.message}`, 'error');
        }
    }



    async function deleteModel(modelName, event) {
        event.stopPropagation(); // Prevent row click from selecting model

        if (!confirm(`Are you sure you want to delete ${modelName}? This action cannot be undone.`)) {
            return;
        }

        try {
            const res = await fetch('/api/settings/models', {
                method: 'DELETE',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ model: modelName })
            });

            if (res.ok) {
                showToast(`‚úÖ Deleted ${modelName}`);
                loadModels(); // Refresh list

                // If deleted active model, clear selection
                if (currentSelectedModel === modelName) {
                    currentSelectedModel = null;
                    updateCurrentModelDisplay();
                }
            } else {
                const err = await res.json();
                showToast(`‚ùå Failed to delete: ${err.error}`, 'error');
            }
        } catch (e) {
            console.error(e);
            showToast('‚ùå Error deleting model', 'error');
        }
    }

    function updateDownloadProgress(modelName, progress) {
        console.log('updateDownloadProgress called for:', modelName, 'with progress:', progress);

        if (!activeDownloads.has(modelName)) {
            console.log('Model not in active downloads, this should not happen if startPull was called first');
            // If somehow it's not in the map, add it but this shouldn't occur normally
            const downloadId = Date.now().toString();
            activeDownloads.set(modelName, {
                id: downloadId,
                status: progress.status || 'downloading',
                progress: progress
            });
        } else {
            const download = activeDownloads.get(modelName);

            // The /status endpoint returns the actual Ollama progress when task status is PROGRESS
            // Check if progress has Ollama download data (completed, total fields)
            if (progress.completed !== undefined && progress.total !== undefined) {
                // This is Ollama download progress data
                download.progress = {
                    status: progress.status, // actual download status like "pulling [digest]"
                    completed: progress.completed,
                    total: progress.total,
                    digest: progress.digest
                };
                // Use the actual download status
                download.status = progress.status;
            } else if (progress.status === 'PROGRESS' && progress.progress_line) {
                // Legacy: Handle old format if progress_line exists
                try {
                    const ollamaProgress = JSON.parse(progress.progress_line);
                    download.progress = ollamaProgress;
                    download.status = ollamaProgress.status || 'downloading';
                } catch (e) {
                    download.progress = progress;
                    download.status = progress.status || 'downloading';
                }
            } else {
                // Regular progress update or final status
                download.status = progress.status || 'downloading';
                download.progress = progress;

                // Handle different Ollama progress statuses
                if (progress.status === 'success') {
                    download.status = 'complete';
                } else if (progress.status === 'error') {
                    download.status = 'error';
                    download.error = progress.error;
                }
            }
        }

        updateDownloadsUI();
    }

    function updateDownloadsUI() {
        console.log('updateDownloadsUI called with activeDownloads size:', activeDownloads.size);
        activeDownloads.forEach((download, modelName) => {
            console.log('Download:', modelName, 'Progress:', download.progress);
        });

        const tracker = document.getElementById('downloads-tracker');
        const list = document.getElementById('downloads-list');
        const count = document.getElementById('download-count');

        if (activeDownloads.size === 0) {
            console.log('No active downloads, hiding tracker');
            tracker.classList.add('hidden');
            return;
        }

        console.log('Showing tracker with', activeDownloads.size, 'downloads');
        tracker.classList.remove('hidden');
        count.textContent = activeDownloads.size;

        let html = '';
        activeDownloads.forEach((download, modelName) => {
            const progress = download.progress || {};
            const status = progress.status || 'starting';

            let statusText = 'Starting...';
            let progressPercent = 0;
            let progressClass = 'progress-primary';

            // Handle Ollama's various status formats
            if (status === 'pulling manifest') {
                statusText = 'Fetching manifest...';
                progressPercent = 5;
            } else if (status.includes('pulling') && progress.total && progress.completed !== undefined) {
                // Handle "pulling [digest]" status with progress
                const completed = progress.completed || 0;
                const total = progress.total || 1;
                progressPercent = Math.round((completed / total) * 100);
                statusText = `Downloading... ${formatBytes(completed)} / ${formatBytes(total)}`;
            } else if (status === 'downloading') {
                const completed = progress.completed || 0;
                const total = progress.total || 1;
                progressPercent = Math.round((completed / total) * 100);
                statusText = `Downloading... ${formatBytes(completed)} / ${formatBytes(total)}`;
            } else if (status === 'verifying sha256 digest') {
                statusText = 'Verifying...';
                progressPercent = 95;
            } else if (status === 'writing manifest') {
                statusText = 'Finalizing...';
                progressPercent = 98;
            } else if (status === 'success') {
                statusText = 'Complete!';
                progressPercent = 100;
                progressClass = 'progress-success';
            } else if (status === 'error') {
                statusText = 'Error: ' + (download.error || 'Unknown error');
                progressClass = 'progress-error';
            } else {
                // For other statuses like "pulling manifest" or "receiving data"
                statusText = status.charAt(0).toUpperCase() + status.slice(1) + '...';
            }

            html += `
            <div class="card bg-base-100 border border-base-300 p-3">
                <div class="flex justify-between items-center mb-2">
                    <span class="font-semibold text-sm">${modelName}</span>
                    <span class="text-xs text-base-content/60">${statusText}</span>
                </div>
                <progress class="progress ${progressClass} w-full" value="${progressPercent}" max="100"></progress>
                <div class="text-xs text-base-content/60 mt-1">${progressPercent}%</div>
            </div>`;
        });

        console.log('Setting HTML for downloads list:', html);
        list.innerHTML = html;
    }

    async function pollDownloadProgress(displayName, taskId) {
        const pollInterval = 1000; // Poll every second
        const maxAttempts = 1800; // Max 30 minutes (30 min * 60 sec / 1 sec interval)
        let attempts = 0;

        while (attempts < maxAttempts) {
            try {
                const response = await fetch(`/api/settings/pull/status/${taskId}`);
                if (!response.ok) {
                    throw new Error(`Failed to get status: ${response.status}`);
                }

                const statusData = await response.json();
                console.log('Poll response:', statusData);

                // Update progress based on status
                // Backend might overwrite 'status' with Ollama's status (e.g. "pulling..."), so we can't just check for 'PROGRESS'
                // We check if it is NOT a known terminal state
                if (statusData.status === 'SUCCESS') {
                    // Download completed successfully
                    activeDownloads.delete(displayName);
                    updateDownloadsUI();

                    const installedName = statusData.model_name || displayName;
                    showToast(`‚úÖ Downloaded successfully as ${installedName}!`, 'success');

                    loadModels(); // Refresh installed models list
                    return; // Exit polling
                } else if (statusData.status === 'FAILURE') {
                    // Download failed
                    activeDownloads.delete(displayName);
                    updateDownloadsUI();
                    showToast(`‚ùå Failed to download ${displayName}: ${statusData.error}`, 'error');
                    return; // Exit polling
                } else {
                    // Assume it's progress (PROGRESS, PENDING, pulling..., etc.)
                    updateDownloadProgress(displayName, statusData);
                }

                // Wait before next poll
                await new Promise(resolve => setTimeout(resolve, pollInterval));
                attempts++;
            } catch (e) {
                console.error('Error polling download status:', e);
                activeDownloads.delete(displayName);
                updateDownloadsUI();
                showToast(`‚ùå Error checking download status for ${displayName}: ${e.message}`, 'error');
                return; // Exit polling
            }
        }

        // If we reach here, it means we hit the timeout
        activeDownloads.delete(displayName);
        updateDownloadsUI();
        showToast(`‚ùå Download timeout for ${displayName}`, 'error');
    }

    function formatBytes(bytes) {
        if (bytes === 0) return '0 B';
        const k = 1024;
        const sizes = ['B', 'KB', 'MB', 'GB'];
        const i = Math.floor(Math.log(bytes) / Math.log(k));
        return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i];
    }

    async function loadActiveDownloads() {
        try {
            const res = await fetch('/api/settings/pull/active');
            const data = await res.json();

            if (data.active_tasks && data.active_tasks.length > 0) {
                console.log('Restoring active downloads:', data.active_tasks);

                data.active_tasks.forEach(task => {
                    const modelName = task.model_name;
                    // Check if already tracking to avoid duplicates
                    if (!activeDownloads.has(modelName)) {
                        activeDownloads.set(modelName, {
                            id: Date.now().toString(), // Helper ID
                            status: task.status,
                            ollamaName: modelName,
                            taskId: task.task_id,
                            progress: { status: 'restoring...' }
                        });

                        // Resume polling
                        pollDownloadProgress(modelName, task.task_id);
                    }
                });

                updateDownloadsUI();
            }
        } catch (e) {
            console.error("Failed to load active downloads:", e);
        }
    }

    // IMPORT SCANE & EXECUTE
    async function scanImports() {
        const listDiv = document.getElementById('import-list');
        listDiv.innerHTML = '<span class="loading loading-spinner loading-xs"></span>';
        try {
            const res = await fetch('/api/settings/import/scan');
            const data = await res.json();

            if (!data.files || data.files.length === 0) {
                listDiv.innerHTML = '<div class="alert alert-info text-xs">No .gguf files found in rag_app/ollama_models/import</div>';
                return;
            }

            let html = '';
            data.files.forEach(f => {
                html += `
                <div class="flex items-center justify-between bg-base-200 p-2 rounded">
                    <span class="font-mono text-sm break-all">${f}</span>
                    <div class="join">
                        <input type="text" placeholder="Name for Ollama" class="input input-xs input-bordered join-item" id="name-${f}" value="${f.replace('.gguf', '').toLowerCase()}">
                        <button class="btn btn-xs btn-primary join-item" onclick="importGGUF('${f}')">Import</button>
                    </div>
                </div>`;
            });
            listDiv.innerHTML = html;
        } catch (e) { listDiv.innerHTML = "Error scanning: " + e.message; }
    }

    async function importGGUF(filename) {
        const modelName = document.getElementById(`name-${filename}`).value;
        if (!modelName) return alert("Please give it a name");

        if (!confirm(`Create model '${modelName}' from '${filename}'? This can take a minute.`)) return;

        try {
            const response = await fetch('/api/settings/import', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ filename: filename, model_name: modelName })
            });
            if (!response.ok) throw new Error("Import failed");

            // Read stream
            const reader = response.body.getReader();
            while (true) {
                const { value, done } = await reader.read();
                if (done) break;
            }

            alert("Imported successfully!");
            loadModels(); // Refresh installed list

        } catch (e) { alert(e.message); }
    }

    // ============= CHAT SETTINGS FUNCTIONS =============

    let currentSettings = {
        use_conversation_context: true,
        max_context_messages: 10,
        selected_system_prompt_id: null
    };
    let currentEditingPromptId = null;


    function toggleContextSettings() {
        const enabled = document.getElementById('use-context-toggle').checked;
        const container = document.getElementById('context-range-container');
        if (enabled) {
            container.classList.remove('opacity-50', 'pointer-events-none');
        } else {
            container.classList.add('opacity-50', 'pointer-events-none');
        }
    }

    async function loadChatSettings() {
        try {
            const res = await fetch('/api/settings/chat');
            const data = await res.json();

            // Context settings
            document.getElementById('use-context-toggle').checked = data.use_conversation_context;
            document.getElementById('max-context-range').value = data.max_context_messages;
            toggleContextSettings(); // Update UI state
            updateRangeValue();     // Update label

            // RAG Settings
            if (data.whisper_model) {
                document.getElementById('whisper-model-select').value = data.whisper_model;
            }
            if (data.chunk_size) {
                document.getElementById('chunk-size-range').value = data.chunk_size;
                document.getElementById('chunk-size-input').value = data.chunk_size;
            }
            if (data.chunk_overlap) {
                document.getElementById('chunk-overlap-range').value = data.chunk_overlap;
                document.getElementById('chunk-overlap-input').value = data.chunk_overlap;
            }

            // Store prompt selection for later when prompts load
            if (data.selected_system_prompt_id) {
                window.targetPromptId = data.selected_system_prompt_id;
            }

            // LLM Configuration
            if (data.llm_provider) {
                document.getElementById('llm-provider-select').value = data.llm_provider;
            }
            if (data.openai_api_key) document.getElementById('openai-api-key').value = data.openai_api_key;
            if (data.anthropic_api_key) document.getElementById('anthropic-api-key').value = data.anthropic_api_key;
            if (data.local_llm_base_url) document.getElementById('local-llm-base-url').value = data.local_llm_base_url;

            updateLLMConfigVisibility(); // Set initial visibility state
        } catch (e) { console.error(e); }
    }

    async function saveChatSettings() {
        const useCtx = document.getElementById('use-context-toggle').checked;
        const maxCtx = document.getElementById('max-context-range').value;
        const chunkSize = document.getElementById('chunk-size-input').value; // Read from exact input
        const chunkOverlap = document.getElementById('chunk-overlap-input').value;
        const whisperModel = document.getElementById('whisper-model-select').value;

        // Find selected prompt card
        const selectedRadio = document.querySelector('input[name="prompt-select"]:checked');
        const promptId = selectedRadio ? selectedRadio.value : null;

        try {
            const res = await fetch('/api/settings/chat', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    use_conversation_context: useCtx,
                    max_context_messages: maxCtx,
                    selected_system_prompt_id: promptId,
                    chunk_size: chunkSize,
                    chunk_overlap: chunkOverlap,
                    chunk_overlap: chunkOverlap,
                    whisper_model: whisperModel,
                    llm_provider: document.getElementById('llm-provider-select').value,
                    openai_api_key: document.getElementById('openai-api-key').value,
                    anthropic_api_key: document.getElementById('anthropic-api-key').value,
                    local_llm_base_url: document.getElementById('local-llm-base-url').value
                })
            });

            if (res.ok) {
                showToast('‚úÖ Settings saved!');
            } else {
                showToast('‚ùå Failed to save', 'error');
            }
        } catch (e) {
            console.error(e);
            showToast('Error saving settings', 'error');
        }
    }

    function updateRangeValue() {
        const val = document.getElementById('max-context-range').value;
        document.getElementById('context-range-value').textContent = val + " messages";
    }

    function updateRahSettingsDisplay(source) {
        // Sync Size
        if (source === 'size') {
            document.getElementById('chunk-size-input').value = document.getElementById('chunk-size-range').value;
        } else if (source === 'size_input') {
            document.getElementById('chunk-size-range').value = document.getElementById('chunk-size-input').value;
        }

        // Sync Overlap
        if (source === 'overlap') {
            document.getElementById('chunk-overlap-input').value = document.getElementById('chunk-overlap-range').value;
        } else if (source === 'overlap_input') {
            document.getElementById('chunk-overlap-range').value = document.getElementById('chunk-overlap-input').value;
        }
    }

    function updateLLMConfigVisibility() {
        const provider = document.getElementById('llm-provider-select').value;
        const openai = document.getElementById('config-openai');
        const anthropic = document.getElementById('config-anthropic');
        const local = document.getElementById('config-local-url');

        // Reset all to hidden
        openai.classList.add('hidden');
        anthropic.classList.add('hidden');
        local.classList.add('hidden');

        if (provider === 'openai') {
            openai.classList.remove('hidden');
        } else if (provider === 'anthropic') {
            anthropic.classList.remove('hidden');
        } else if (provider === 'lm_studio') {
            local.classList.remove('hidden');
        } else if (provider === 'ollama') {
            // Ollama usually uses default host/port or env override, but 
            // if we want to allow override here, we could show local URL.
            // For now, let's allow "Base URL" override for advanced users or hide it for simplicity.
            // Given the requirement for generic config:
            local.classList.remove('hidden');
        }
    }



    // ============= SYSTEM PROMPTS FUNCTIONS =============

    async function loadPrompts() {
        const container = document.getElementById('prompts-list');
        container.innerHTML = '<span class="loading loading-spinner loading-md"></span>';

        try {
            const res = await fetch('/api/settings/prompts');
            const data = await res.json();

            if (!data.prompts || data.prompts.length === 0) {
                container.innerHTML = '<p class="text-sm text-base-content/60">No system prompts found.</p>';
                return;
            }

            let html = '';
            data.prompts.forEach(prompt => {
                const isSelected = prompt.id === currentSettings.selected_system_prompt_id;
                const isDefault = prompt.is_default;

                html += `
                <div class="flex items-center gap-3 p-3 rounded-lg bg-base-100 border ${isSelected ? 'border-primary bg-primary/10' : 'border-base-300'} hover:border-primary transition-colors cursor-pointer"
                     onclick="selectPrompt('${prompt.id}')">
                    <input type="radio" name="prompt-select" class="radio radio-primary radio-sm" ${isSelected ? 'checked' : ''}>
                    <div class="flex-1">
                        <div class="flex items-center gap-2">
                            <span class="font-semibold text-sm">${prompt.title}</span>
                            ${isDefault ? '<span class="badge badge-ghost badge-xs">Default</span>' : ''}
                            ${isSelected ? '<span class="badge badge-success badge-xs">Active</span>' : ''}
                        </div>
                        <p class="text-xs text-base-content/60 line-clamp-2 mt-1">${prompt.content}</p>
                    </div>
                    <div class="flex gap-1">
                        ${!isDefault ? `
                            <button class="btn btn-ghost btn-xs" onclick="event.stopPropagation(); editPrompt('${prompt.id}')" title="Edit">
                                <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-4 h-4">
                                    <path stroke-linecap="round" stroke-linejoin="round" d="M16.862 4.487l1.687-1.688a1.875 1.875 0 112.652 2.652L10.582 16.07a4.5 4.5 0 01-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 011.13-1.897l8.932-8.931zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0115.75 21H5.25A2.25 2.25 0 013 18.75V8.25A2.25 2.25 0 015.25 6H10" />
                                </svg>
                            </button>
                            <button class="btn btn-ghost btn-xs text-error" onclick="event.stopPropagation(); deletePrompt('${prompt.id}')" title="Delete">
                                <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-4 h-4">
                                    <path stroke-linecap="round" stroke-linejoin="round" d="M14.74 9l-.346 9m-4.788 0L9.26 9m9.968-3.21c.342.052.682.107 1.022.166m-1.022-.165L18.16 19.673a2.25 2.25 0 01-2.244 2.077H8.084a2.25 2.25 0 01-2.244-2.077L4.772 5.79m14.456 0a48.108 48.108 0 00-3.478-.397m-12 .562c.34-.059.68-.114 1.022-.165m0 0a48.11 48.11 0 013.478-.397m7.5 0v-.916c0-1.18-.91-2.164-2.09-2.201a51.964 51.964 0 00-3.32 0c-1.18.037-2.09 1.022-2.09 2.201v.916m7.5 0a48.667 48.667 0 00-7.5 0" />
                                </svg>
                            </button>
                        ` : ''}
                    </div>
                </div>`;
            });

            container.innerHTML = html;
        } catch (e) {
            console.error('Error loading prompts:', e);
            container.innerHTML = '<p class="text-sm text-error">Error loading prompts</p>';
        }
    }

    function selectPrompt(promptId) {
        currentSettings.selected_system_prompt_id = promptId;
        loadPrompts(); // Refresh to update UI
    }

    function showCreatePromptModal() {
        currentEditingPromptId = null;
        document.getElementById('modal-title').textContent = 'Create System Prompt';
        document.getElementById('prompt-title-input').value = '';
        document.getElementById('prompt-content-input').value = '';
        document.getElementById('prompt-modal').showModal();
    }

    async function editPrompt(promptId) {
        try {
            const res = await fetch('/api/settings/prompts');
            const data = await res.json();
            const prompt = data.prompts.find(p => p.id === promptId);

            if (prompt) {
                currentEditingPromptId = promptId;
                document.getElementById('modal-title').textContent = 'Edit System Prompt';
                document.getElementById('prompt-title-input').value = prompt.title;
                document.getElementById('prompt-content-input').value = prompt.content;
                document.getElementById('prompt-modal').showModal();
            }
        } catch (e) {
            console.error('Error loading prompt:', e);
            showToast('Error loading prompt', 'error');
        }
    }

    async function savePrompt() {
        const title = document.getElementById('prompt-title-input').value.trim();
        const content = document.getElementById('prompt-content-input').value.trim();

        if (!title || !content) {
            showToast('Title and content are required', 'warning');
            return;
        }

        try {
            let res;
            if (currentEditingPromptId) {
                // Update existing
                res = await fetch(`/api/settings/prompts/${currentEditingPromptId}`, {
                    method: 'PUT',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ title, content })
                });
            } else {
                // Create new
                res = await fetch('/api/settings/prompts', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ title, content })
                });
            }

            if (res.ok) {
                closePromptModal();
                loadPrompts();
                showToast('Prompt saved successfully!', 'success');
            } else {
                const error = await res.json();
                showToast(error.error || 'Failed to save prompt', 'error');
            }
        } catch (e) {
            console.error('Error saving prompt:', e);
            showToast('Error saving prompt', 'error');
        }
    }

    async function deletePrompt(promptId) {
        if (!confirm('Are you sure you want to delete this prompt?')) return;

        try {
            const res = await fetch(`/api/settings/prompts/${promptId}`, {
                method: 'DELETE'
            });

            if (res.ok) {
                loadPrompts();
                showToast('Prompt deleted', 'success');
            } else {
                const error = await res.json();
                showToast(error.error || 'Failed to delete prompt', 'error');
            }
        } catch (e) {
            console.error('Error deleting prompt:', e);
            showToast('Error deleting prompt', 'error');
        }
    }

    function closePromptModal() {
        document.getElementById('prompt-modal').close();
    }

    // ============= TOAST NOTIFICATIONS =============

    function showToast(message, type = 'info') {
        const container = document.getElementById('toast-container') || createToastContainer();

        const toast = document.createElement('div');
        toast.className = `alert alert-${type} shadow-lg mb-2 animate-slideIn`;

        let icon = '';
        if (type === 'success') {
            icon = '<svg xmlns="http://www.w3.org/2000/svg" class="stroke-current shrink-0 h-6 w-6" fill="none" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z" /></svg>';
        } else if (type === 'error') {
            icon = '<svg xmlns="http://www.w3.org/2000/svg" class="stroke-current shrink-0 h-6 w-6" fill="none" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 14l2-2m0 0l2-2m-2 2l-2-2m2 2l2 2m7-2a9 9 0 11-18 0 9 9 0 0118 0z" /></svg>';
        } else if (type === 'warning') {
            icon = '<svg xmlns="http://www.w3.org/2000/svg" class="stroke-current shrink-0 h-6 w-6" fill="none" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z" /></svg>';
        }

        toast.innerHTML = `
            ${icon}
            <span>${message}</span>
        `;

        container.appendChild(toast);

        setTimeout(() => {
            toast.classList.add('animate-slideOut');
            setTimeout(() => toast.remove(), 300);
        }, 3000);
    }

    function createToastContainer() {
        const container = document.createElement('div');
        container.id = 'toast-container';
        container.className = 'fixed top-4 right-4 z-50 flex flex-col';
        document.body.appendChild(container);
        return container;
    }
    document.addEventListener('DOMContentLoaded', () => {
        loadChatSettings();
        loadPrompts();
    });
</script>

<style>
    @keyframes slideIn {
        from {
            transform: translateX(100%);
            opacity: 0;
        }

        to {
            transform: translateX(0);
            opacity: 1;
        }
    }

    @keyframes slideOut {
        from {
            transform: translateX(0);
            opacity: 1;
        }

        to {
            transform: translateX(100%);
            opacity: 0;
        }
    }

    .animate-slideIn {
        animation: slideIn 0.3s ease-out;
    }

    .animate-slideOut {
        animation: slideOut 0.3s ease-in;
    }
</style>
{% endblock %}